{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data from excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>Trading_Volume</th>\n",
       "      <th>Trading_money</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>close</th>\n",
       "      <th>spread</th>\n",
       "      <th>Trading_turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>407</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>919</td>\n",
       "      <td>60450567</td>\n",
       "      <td>1564288528</td>\n",
       "      <td>25.83</td>\n",
       "      <td>25.95</td>\n",
       "      <td>25.80</td>\n",
       "      <td>25.85</td>\n",
       "      <td>0.05</td>\n",
       "      <td>21261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>408</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>919</td>\n",
       "      <td>104525328</td>\n",
       "      <td>2732154338</td>\n",
       "      <td>25.86</td>\n",
       "      <td>26.27</td>\n",
       "      <td>25.86</td>\n",
       "      <td>26.14</td>\n",
       "      <td>0.29</td>\n",
       "      <td>25849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>409</td>\n",
       "      <td>2024-07-02</td>\n",
       "      <td>919</td>\n",
       "      <td>74441424</td>\n",
       "      <td>1939078004</td>\n",
       "      <td>26.14</td>\n",
       "      <td>26.21</td>\n",
       "      <td>25.92</td>\n",
       "      <td>26.00</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>29449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>2024-07-03</td>\n",
       "      <td>919</td>\n",
       "      <td>36864723</td>\n",
       "      <td>961097654</td>\n",
       "      <td>26.13</td>\n",
       "      <td>26.17</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>15362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>411</td>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>919</td>\n",
       "      <td>60116599</td>\n",
       "      <td>1568696435</td>\n",
       "      <td>26.12</td>\n",
       "      <td>26.17</td>\n",
       "      <td>26.02</td>\n",
       "      <td>26.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>18940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        date  stock_id  Trading_Volume  Trading_money   open  \\\n",
       "407         407  2024-06-28       919        60450567     1564288528  25.83   \n",
       "408         408  2024-07-01       919       104525328     2732154338  25.86   \n",
       "409         409  2024-07-02       919        74441424     1939078004  26.14   \n",
       "410         410  2024-07-03       919        36864723      961097654  26.13   \n",
       "411         411  2024-07-04       919        60116599     1568696435  26.12   \n",
       "\n",
       "       max    min  close  spread  Trading_turnover  \n",
       "407  25.95  25.80  25.85    0.05             21261  \n",
       "408  26.27  25.86  26.14    0.29             25849  \n",
       "409  26.21  25.92  26.00   -0.14             29449  \n",
       "410  26.17  26.00  26.02    0.02             15362  \n",
       "411  26.17  26.02  26.03    0.01             18940  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excel\n",
    "xl = 'stk-2024-07-05.xlsx'\n",
    "\n",
    "stock_data = pd.read_excel(xl)\n",
    "stock_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Network(前饋神經網路)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 選擇特徵/數據\n",
    "x = stock_data[['open', 'max', 'min', 'Trading_Volume']]\n",
    "y = stock_data['close']\n",
    "\n",
    "# 特徵縮放\n",
    "scaler = MinMaxScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "# 切割數據:訓練/測試\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\python\\DS\\stock\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 431.7780 - val_accuracy: 0.0000e+00 - val_loss: 404.2963\n",
      "Epoch 2/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 390.2589 - val_accuracy: 0.0000e+00 - val_loss: 350.4328\n",
      "Epoch 3/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 327.1508 - val_accuracy: 0.0000e+00 - val_loss: 247.5018\n",
      "Epoch 4/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 209.3936 - val_accuracy: 0.0000e+00 - val_loss: 113.4330\n",
      "Epoch 5/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 85.4695 - val_accuracy: 0.0000e+00 - val_loss: 25.2701\n",
      "Epoch 6/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 20.7072 - val_accuracy: 0.0000e+00 - val_loss: 13.2316\n",
      "Epoch 7/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 10.6483 - val_accuracy: 0.0000e+00 - val_loss: 11.5530\n",
      "Epoch 8/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 10.5356 - val_accuracy: 0.0000e+00 - val_loss: 9.8350\n",
      "Epoch 9/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 8.0460 - val_accuracy: 0.0000e+00 - val_loss: 8.4116\n",
      "Epoch 10/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 6.5395 - val_accuracy: 0.0000e+00 - val_loss: 6.8921\n",
      "Epoch 11/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 5.4211 - val_accuracy: 0.0000e+00 - val_loss: 5.6219\n",
      "Epoch 12/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 4.1821 - val_accuracy: 0.0000e+00 - val_loss: 4.4452\n",
      "Epoch 13/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 3.8365 - val_accuracy: 0.0000e+00 - val_loss: 3.3946\n",
      "Epoch 14/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 3.1127 - val_accuracy: 0.0000e+00 - val_loss: 2.4993\n",
      "Epoch 15/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 2.1794 - val_accuracy: 0.0000e+00 - val_loss: 1.7255\n",
      "Epoch 16/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 1.3961 - val_accuracy: 0.0000e+00 - val_loss: 1.1772\n",
      "Epoch 17/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.8932 - val_accuracy: 0.0000e+00 - val_loss: 0.7373\n",
      "Epoch 18/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.6582 - val_accuracy: 0.0000e+00 - val_loss: 0.4382\n",
      "Epoch 19/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.3851 - val_accuracy: 0.0000e+00 - val_loss: 0.2796\n",
      "Epoch 20/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.2223 - val_accuracy: 0.0000e+00 - val_loss: 0.1503\n",
      "Epoch 21/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1409 - val_accuracy: 0.0000e+00 - val_loss: 0.0856\n",
      "Epoch 22/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0647 - val_accuracy: 0.0000e+00 - val_loss: 0.0523\n",
      "Epoch 23/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0376 - val_accuracy: 0.0000e+00 - val_loss: 0.0356\n",
      "Epoch 24/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0241 - val_accuracy: 0.0000e+00 - val_loss: 0.0286\n",
      "Epoch 25/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0205 - val_accuracy: 0.0000e+00 - val_loss: 0.0240\n",
      "Epoch 26/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0157 - val_accuracy: 0.0000e+00 - val_loss: 0.0215\n",
      "Epoch 27/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0139 - val_accuracy: 0.0000e+00 - val_loss: 0.0206\n",
      "Epoch 28/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0140 - val_accuracy: 0.0000e+00 - val_loss: 0.0199\n",
      "Epoch 29/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0133 - val_accuracy: 0.0000e+00 - val_loss: 0.0195\n",
      "Epoch 30/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0160 - val_accuracy: 0.0000e+00 - val_loss: 0.0194\n",
      "Epoch 31/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0127 - val_accuracy: 0.0000e+00 - val_loss: 0.0190\n",
      "Epoch 32/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0130 - val_accuracy: 0.0000e+00 - val_loss: 0.0185\n",
      "Epoch 33/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.0139 - val_accuracy: 0.0000e+00 - val_loss: 0.0187\n",
      "Epoch 34/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.0164 - val_accuracy: 0.0000e+00 - val_loss: 0.0185\n",
      "Epoch 35/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0117 - val_accuracy: 0.0000e+00 - val_loss: 0.0179\n",
      "Epoch 36/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0142 - val_accuracy: 0.0000e+00 - val_loss: 0.0175\n",
      "Epoch 37/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0146 - val_accuracy: 0.0000e+00 - val_loss: 0.0171\n",
      "Epoch 38/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0108 - val_accuracy: 0.0000e+00 - val_loss: 0.0171\n",
      "Epoch 39/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0139 - val_accuracy: 0.0000e+00 - val_loss: 0.0172\n",
      "Epoch 40/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0135 - val_accuracy: 0.0000e+00 - val_loss: 0.0169\n",
      "Epoch 41/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0123 - val_accuracy: 0.0000e+00 - val_loss: 0.0162\n",
      "Epoch 42/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0133 - val_accuracy: 0.0000e+00 - val_loss: 0.0162\n",
      "Epoch 43/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0140 - val_accuracy: 0.0000e+00 - val_loss: 0.0161\n",
      "Epoch 44/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0127 - val_accuracy: 0.0000e+00 - val_loss: 0.0163\n",
      "Epoch 45/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0092 - val_accuracy: 0.0000e+00 - val_loss: 0.0159\n",
      "Epoch 46/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0107 - val_accuracy: 0.0000e+00 - val_loss: 0.0158\n",
      "Epoch 47/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0132 - val_accuracy: 0.0000e+00 - val_loss: 0.0159\n",
      "Epoch 48/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0088 - val_accuracy: 0.0000e+00 - val_loss: 0.0157\n",
      "Epoch 49/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0114 - val_accuracy: 0.0000e+00 - val_loss: 0.0165\n",
      "Epoch 50/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0119 - val_accuracy: 0.0000e+00 - val_loss: 0.0156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x196841edeb0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0164 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01728729158639908, 0.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model.evaluate(x_test, y_test)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:[[0.59392945 0.58886159 0.58746949 0.2972709 ]\n",
      " [0.14191961 0.15315315 0.14890155 0.00450059]\n",
      " [0.47005742 0.46519247 0.46216436 0.13311088]\n",
      " [0.17555373 0.17035217 0.15703824 0.00862806]\n",
      " [0.6021329  0.5978706  0.59235151 0.25982891]\n",
      " [0.81296144 0.81244881 0.80553295 0.06807988]\n",
      " [0.53814602 0.54054054 0.53539463 0.06787414]\n",
      " [0.35110747 0.34971335 0.34825061 0.00500044]\n",
      " [0.49876948 0.5045045  0.50284784 0.04956288]\n",
      " [0.45447088 0.45454545 0.44914565 0.09983046]\n",
      " [0.17965546 0.17936118 0.18063466 0.00717993]\n",
      " [0.5561936  0.55446355 0.55899105 0.07159084]\n",
      " [0.76210008 0.75921376 0.72742067 0.27153072]\n",
      " [0.30598852 0.31122031 0.29861676 0.00350195]\n",
      " [0.23297785 0.22768223 0.21969081 0.00545863]\n",
      " [0.1657096  0.16871417 0.16517494 0.00293343]\n",
      " [0.60295324 0.6036036  0.60618389 0.07184754]\n",
      " [0.6242822  0.61834562 0.6086249  0.18711639]\n",
      " [0.61197703 0.60687961 0.60943857 0.06432873]\n",
      " [0.25758819 0.28255528 0.26362897 0.00631727]\n",
      " [0.87612797 0.87714988 0.86493084 0.12828452]\n",
      " [0.0073831  0.01392301 0.01545972 0.00496455]\n",
      " [0.92780968 0.92465192 0.91781937 0.07028814]\n",
      " [0.23625923 0.25552826 0.24247356 0.00431274]\n",
      " [0.52173913 0.51678952 0.51179821 0.15749184]\n",
      " [0.36669401 0.36691237 0.36940602 0.00300361]\n",
      " [0.74159147 0.74610975 0.72823434 0.11897188]\n",
      " [0.7973749  0.81572482 0.7990236  0.11788216]\n",
      " [0.89663659 0.9025389  0.89585028 0.11543603]\n",
      " [0.49302707 0.51023751 0.48820179 0.03203245]\n",
      " [0.90319934 0.90663391 0.90154597 0.1163389 ]\n",
      " [0.4585726  0.45782146 0.453214   0.03237076]\n",
      " [0.24282199 0.25225225 0.24735557 0.00296868]\n",
      " [0.59474979 0.59131859 0.59235151 0.09618521]\n",
      " [0.59639048 0.59295659 0.59397884 0.27556022]\n",
      " [0.63822806 0.63554464 0.63628967 0.13973125]\n",
      " [0.59721083 0.6044226  0.59641985 0.06956217]\n",
      " [0.29614438 0.29074529 0.28885273 0.00218997]\n",
      " [0.08941756 0.08927109 0.09031733 0.01073086]\n",
      " [0.83757178 0.83292383 0.79576892 0.52452511]\n",
      " [0.01312551 0.01146601 0.0081367  0.09942537]\n",
      " [0.46841674 0.47174447 0.47030106 0.02816077]\n",
      " [0.99917966 0.99344799 0.91781937 1.        ]\n",
      " [0.44134537 0.43980344 0.43775427 0.11745324]\n",
      " [0.87366694 0.86732187 0.84865745 0.50722154]\n",
      " [0.85972108 0.86240786 0.85760781 0.08228281]\n",
      " [0.24528302 0.23996724 0.23840521 0.00549609]\n",
      " [0.33716161 0.34070434 0.33197722 0.0075085 ]\n",
      " [0.37161608 0.36609337 0.36126932 0.0048279 ]\n",
      " [0.30516817 0.3005733  0.29536208 0.00399014]\n",
      " [0.58982773 0.5978706  0.59235151 0.22590737]\n",
      " [0.95816243 0.96805897 0.95606184 0.17668663]\n",
      " [0.3240361  0.32760033 0.31570382 0.00292419]\n",
      " [0.13863823 0.13513514 0.13588283 0.00456142]\n",
      " [0.4290402  0.43161343 0.4182262  0.05195761]\n",
      " [0.3240361  0.32596233 0.32953621 0.00336563]\n",
      " [0.14027892 0.14250614 0.14239219 0.00122966]\n",
      " [0.98687449 0.99262899 0.98616762 0.31840698]\n",
      " [0.14602133 0.15724816 0.15296989 0.01268296]\n",
      " [0.45365053 0.45045045 0.45240033 0.17982728]\n",
      " [0.42821985 0.43898444 0.43287225 0.01005775]\n",
      " [0.30926989 0.31203931 0.31489015 0.00619471]\n",
      " [0.23954061 0.23669124 0.24247356 0.0027217 ]\n",
      " [0.50369155 0.5045045  0.49633849 0.08522912]\n",
      " [0.14684167 0.14332514 0.13913751 0.00615886]\n",
      " [0.14109926 0.13841114 0.13995118 0.00337063]\n",
      " [0.23543888 0.23832924 0.23921888 0.00163587]\n",
      " [0.68744873 0.71744472 0.68917819 0.19309053]\n",
      " [0.47744053 0.48484848 0.47111473 0.12106685]\n",
      " [0.37243642 0.36855037 0.37103336 0.05718361]\n",
      " [0.17063167 0.17362817 0.17331164 0.00245732]\n",
      " [0.90566038 0.93284193 0.90642799 0.20239375]\n",
      " [0.14191961 0.14004914 0.14646054 0.00385408]\n",
      " [0.11730927 0.12039312 0.12286412 0.00855116]\n",
      " [0.91796555 0.91564292 0.89666395 0.21640313]\n",
      " [0.90484003 0.8992629  0.89340928 0.24129762]\n",
      " [0.17637408 0.17444717 0.17656631 0.0039111 ]\n",
      " [0.62018048 0.61670762 0.61676159 0.36868438]\n",
      " [0.42657916 0.43243243 0.43043124 0.13247561]\n",
      " [0.4511895  0.45945946 0.43124491 0.02977347]\n",
      " [0.30270714 0.31040131 0.3083808  0.00448792]\n",
      " [0.89417555 0.9049959  0.89096827 0.12139147]\n",
      " [0.41181296 0.41113841 0.40927583 0.01910083]]\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "預測:[21.99919], 實際:21.99\n",
      "預測:[16.622961], 實際:16.72\n",
      "預測:[20.506485], 實際:20.41\n",
      "預測:[16.862663], 實際:16.67\n",
      "預測:[22.09556], 實際:22.02\n",
      "預測:[24.751055], 實際:24.73\n",
      "預測:[21.4064], 實際:21.35\n",
      "預測:[19.107895], 實際:19.05\n",
      "預測:[20.969791], 實際:20.95\n",
      "預測:[20.351423], 實際:20.25\n"
     ]
    }
   ],
   "source": [
    "print(f\"input:{x_test}\")\n",
    "result = model.predict(x_test)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"預測:{result[i]}, 實際:{y_test.iloc[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
